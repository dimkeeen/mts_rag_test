# main.py

import os
import logging
from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from dotenv import load_dotenv
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from hybrid_retriever import HybridRetriever, faiss_retriever, bm25_retriever
from fastapi.staticfiles import StaticFiles

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI ===
app = FastAPI()
templates = Jinja2Templates(directory=".")

# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ –º–æ–Ω—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–∞–ø–∫—É —Å–æ —Å—Ç–∏–ª—è–º–∏
app.mount("/static", StaticFiles(directory="."), name="static")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY is required")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ===
llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.7, max_tokens=1000)
hybrid_retriever = HybridRetriever(faiss_retriever, bm25_retriever)

# === –†–æ—É—Ç –¥–ª—è HTML-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ===
@app.get("/", response_class=HTMLResponse)
async def serve_ui(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# ‚úÖ POST-–∑–∞–ø—Ä–æ—Å —Ç–µ–ø–µ—Ä—å –∂–∏–≤—ë—Ç –ø–æ –ø—É—Ç–∏ /ask
@app.post("/ask")
async def handle_query(query: str = Form(...)):
    try:
        log.info(f"üì• –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: {query}")
        relevant_docs = hybrid_retriever.get_relevant_documents(query)
        log.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(relevant_docs)}")

        context = "\n".join(
            f"–í–æ–ø—Ä–æ—Å: {doc.page_content}\n–û—Ç–≤–µ—Ç: {doc.metadata['answer']}" for doc in relevant_docs
        )

        prompt_template = """
–¢—ã –æ–Ω–ª–∞–π–Ω –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –∫–æ–º–ø–∞–Ω–∏–∏ –ú–¢–°.
–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º, –≤–µ–∂–ª–∏–≤–æ –∏ –ª—é–±–µ–∑–Ω–æ –æ—Ç–≤–µ—á–∞—è –Ω–∞ –∏—Ö –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏.
–û—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

{context}

–í–æ–ø—Ä–æ—Å: {query}
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏ –ú–¢–°.

–ï—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–µ—Ä–µ–π—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ "https://support.mts.ru/contacts".
–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–æ–¥—É–∫—Ç–∞–º –ú–¢–° ‚Äî –æ–±—ä—è—Å–Ω–∏, —á—Ç–æ —Ç—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å —Ç–æ–ª—å–∫–æ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –≤–Ω—É—Ç—Ä–∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã –ú–¢–°.
–ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –≤–µ–∂–ª–∏–≤—ã–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""
        prompt = PromptTemplate(input_variables=["context", "query"], template=prompt_template)
        llm_chain = LLMChain(llm=llm, prompt=prompt)
        answer = llm_chain.run({"context": context, "query": query})
        log.info("‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

        relevant_docs_html = "<ul>"
        for doc in relevant_docs:
            relevant_docs_html += f"<li><strong>–í–æ–ø—Ä–æ—Å:</strong> {doc.page_content}<br><strong>–û—Ç–≤–µ—Ç:</strong> {doc.metadata['answer']}</li>"
        relevant_docs_html += "</ul>"

        return JSONResponse(content={
            "answer": answer.strip(),
            "relevant_docs": relevant_docs_html
        })

    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        return JSONResponse(content={
            "answer": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞",
            "relevant_docs": ""
        })

# === –ó–∞–ø—É—Å–∫ –≤—Ä—É—á–Ω—É—é (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ===
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)