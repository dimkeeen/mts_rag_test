import os
import json
import logging
from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv

from langchain.chains import LLMChain
from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
from langchain_openai import ChatOpenAI

from hybrid_retriever import HybridRetriever, faiss_retriever, bm25_retriever

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI ===
app = FastAPI()
templates = Jinja2Templates(directory=".")

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏–∫–∏ (CSS –∏ HTML –∏–∑ –∫–æ—Ä–Ω—è)
app.mount("/static", StaticFiles(directory="static"), name="static")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY is required")

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∏ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ===
llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.3, max_tokens=1000)
hybrid_retriever = HybridRetriever(faiss_retriever, bm25_retriever)

# === –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ===
@app.get("/", response_class=HTMLResponse)
async def serve_ui(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ ===
@app.post("/ask")
async def handle_query(query: str = Form(...)):
    try:
        log.info(f"üì• –ó–∞–ø—Ä–æ—Å: {query}")
        relevant_docs = hybrid_retriever.get_relevant_documents(query)
        log.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(relevant_docs)}")

        context = "\n".join(
            f"–í–æ–ø—Ä–æ—Å: {doc.page_content}\n–û—Ç–≤–µ—Ç: {doc.metadata['answer']}"
            for doc in relevant_docs
        )

        # === –ü—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ System + Human ===
        prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º –∏ —É—Å–ª—É–≥–∞–º –∫–æ–º–ø–∞–Ω–∏–∏ –ú–¢–°. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–ø—Ä—è–º—É—é –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ –ú–¢–°: –º–æ–±–∏–ª—å–Ω–∞—è —Å–≤—è–∑—å, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç, –¢–í, —É–º–Ω—ã–π –¥–æ–º, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç."
                " –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–≤—è–∑–∞–Ω —Å –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏ –ú–¢–° ‚Äî –æ—Ç–≤–µ—Ç—å, —á—Ç–æ —Ç—ã –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–º–µ –ú–¢–° –∏ –Ω–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑—É—Ä–µ—à—å—Å—è –Ω–∞ –¥—Ä—É–≥–∏—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö."
                " –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ù–µ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –≤–Ω–µ —Å–≤–æ–µ–π –æ–±–ª–∞—Å—Ç–∏. –ù–µ –ø–∏—à–∏ —Å—Å—ã–ª–∫–∏."
                " –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown."
            ),
            HumanMessagePromptTemplate.from_template(
                "–í–æ–ø—Ä–æ—Å: {query}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω):\n{context}"
            )
        ])

        llm_chain = LLMChain(llm=llm, prompt=prompt)
        answer = llm_chain.run({"context": context, "query": query})

        log.info("‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫)
        relevant_docs_json = [
            {
                "page_content": doc.page_content,
                "file_path": doc.metadata["file_path"]
            }
            for doc in relevant_docs
        ]

        return JSONResponse(content={
            "answer": answer.strip(),
            "relevant_docs": json.dumps(relevant_docs_json, ensure_ascii=False)
        })

    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        return JSONResponse(content={
            "answer": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.",
            "relevant_docs": "[]"
        })

# === –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)