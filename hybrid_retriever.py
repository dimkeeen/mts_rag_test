import os
import pandas as pd
import logging
from typing import List

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from sentence_transformers import SentenceTransformer

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

CSV_FILE = "mts_questions_answers.csv"
FAISS_INDEX_DIR = "faiss_index"
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
LOCAL_MODEL_PATH = "models/paraphrase-multilingual-mpnet-base-v2"

# === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
log.info("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV...")
df = pd.read_csv(CSV_FILE).fillna("")
documents = [
    Document(
        page_content=row["question_text"],
        metadata={
            "answer": row["answer_text"],
            "file_path": row["file_path"]
        }
    )
    for _, row in df.iterrows()
]
log.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")

# === 2. Embedding –º–æ–¥–µ–ª—å ===
if not os.path.exists(LOCAL_MODEL_PATH):
    log.info(f"‚¨áÔ∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ {LOCAL_MODEL_PATH}...")
    model = SentenceTransformer(MODEL_NAME)
    model.save(LOCAL_MODEL_PATH)
    log.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
else:
    log.info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏–∑ {LOCAL_MODEL_PATH}")

log.info(f"üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ {LOCAL_MODEL_PATH}...")
embedding_model = HuggingFaceEmbeddings(model_name=LOCAL_MODEL_PATH)
log.info("‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# === 3. FAISS –∏–Ω–¥–µ–∫—Å ===
if not os.path.exists(os.path.join(FAISS_INDEX_DIR, "index.faiss")):
    log.info("üÜï FAISS –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")
    vectorstore = FAISS.from_documents(documents, embedding_model)
    vectorstore.save_local(FAISS_INDEX_DIR)
    log.info("‚úÖ FAISS –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
else:
    log.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ FAISS –∏–Ω–¥–µ–∫—Å–∞...")
    vectorstore = FAISS.load_local(FAISS_INDEX_DIR, embedding_model, allow_dangerous_deserialization=True)
    log.info("‚úÖ FAISS –∏–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")

faiss_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# === 4. BM25 Retriever ===
log.info("üìö –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25 —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞...")
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 3
log.info("‚úÖ BM25 —Ä–µ—Ç—Ä–∏–≤–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

# === 5. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ ===
class HybridRetriever:
    def __init__(self, faiss_retriever, bm25_retriever):
        self.faiss_retriever = faiss_retriever
        self.bm25_retriever = bm25_retriever

    def get_relevant_documents(self, query: str, k: int = 3) -> List[Document]:
        log.info(f"\nüîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
        faiss_docs = self.faiss_retriever.get_relevant_documents(query)
        bm25_docs = self.bm25_retriever.get_relevant_documents(query)

        log.info(f"üìé FAISS –≤–µ—Ä–Ω—É–ª {len(faiss_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        log.info(f"üìé BM25 –≤–µ—Ä–Ω—É–ª {len(bm25_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        seen = set()
        unique_docs = []
        for doc in faiss_docs + bm25_docs:
            key = doc.page_content.strip()
            if key not in seen:
                seen.add(key)
                unique_docs.append(doc)

        log.info(f"üîó –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique_docs)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        return unique_docs

# === 6. –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ ===
if __name__ == "__main__":
    log.info("\nüöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞...")
    hybrid_retriever = HybridRetriever(faiss_retriever, bm25_retriever)

    query = "–∫–∞–∫ –ø–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å –º–æ–±–∏–ª—å–Ω–æ–≥–æ?"
    relevant_docs = hybrid_retriever.get_relevant_documents(query)

    log.info("\nüìå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
    for doc in relevant_docs:
        print(f"\nüìå –í–æ–ø—Ä–æ—Å: {doc.page_content}\nüìù –û—Ç–≤–µ—Ç: {doc.metadata['answer']}\nüîó –°—Å—ã–ª–∫–∞: {doc.metadata['file_path']}")
        print("-" * 40)